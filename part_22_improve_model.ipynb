{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Regularization (avoid overfitting)\n",
    "\n",
    "   # 1. L1 & L2 \n",
    "   # 2. Early stopping ( Loss based & weights based)\n",
    "   # 3. Add gradient noise\n",
    "   # 4. Data augmentation \n",
    "   # 5. Ensemble models\n",
    "   # 6. Dropout\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To avoid vansihing gradient \n",
    "\n",
    "# 1.Choosing best activation functions\n",
    "# 2.Weight intialization (xavier and he weight intialization)\n",
    "   # 1.Xavier :\n",
    "   # When give a weight it maintains same variance for all layers\n",
    "\n",
    "   # 2.He :\n",
    "   # it maintains additional amount of variance\n",
    "\n",
    "\n",
    "# 3. Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 - regularization method :\n",
    "#### it moves unnecssary weights(the features which less important ) to exactly zero.\n",
    "#### we will get less no of features.\n",
    "# L2 :\n",
    "   #### it doesnt moves weights into exactly zero , but towards zero.\n",
    "   #### so, all features will get maintain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping :\n",
    "#### ealry stopping will stop the training process ,when the training not imporve.\n",
    "#### ex. for training purpose we gives 100 epochs , so, the no.of iteration will 100, but in actual training , assume that we get good accuracy in 50th epoch, after that improvemnet will not occur ,so, annother 50 epochs are unncesary ,so in this kind of situation early stopping will works very big role.\n",
    "#### Types are : 1.loss based (if loss doent get reduce for specific windows  of iterations then we will stop early)\n",
    "#### 2.weights based (if weights dont improve much than we can stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation :\n",
    "    Is a method used for creating a more data , for changing or translating in a original data.\n",
    "    ex: we can do cropping, rotating,resize our actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout :\n",
    "    In dropout , for each iteration we will disable some amount weights for some layers.so,all weights will try to learn information of input data.\n",
    "    as well as its used for avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
