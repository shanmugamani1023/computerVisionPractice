{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN vs CNN difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "   ##### 1.IN cnn we can extract spatial informations\n",
    "   ##### 2.Weights or parameters gets reduced so,computation time will get reduce\n",
    "   ##### 3.Pooling helps to reduce the dimensions and helps faster and efficient training \n",
    "   ##### 4.Translation invariance - it means convolution helps to detect the object even its translated or zoom in or out or rotated \n",
    "    because of weight sharing (its nothing but we can able to pass same weights or fillters in different region of image so, the model learns features well independent of their location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a **comparison between Artificial Neural Networks (ANNs) and Convolutional Neural Networks (CNNs)** in table format:  \n",
    "\n",
    "| **Aspect**                | **Artificial Neural Network (ANN)**                   | **Convolutional Neural Network (CNN)**              |\n",
    "|---------------------------|------------------------------------------------------|----------------------------------------------------|\n",
    "| **Structure**             | Fully connected layers; every neuron connects to every neuron in the next layer | Uses convolutional layers followed by pooling layers and fully connected layers |\n",
    "| **Input Type**            | Works well with 1D data like tabular data, text, or sequences | Designed for 2D/3D data like images and videos |\n",
    "| **Weight Sharing**        | No weight sharing; each connection has its own weight | Uses weight sharing in convolutional layers to reduce parameters |\n",
    "| **Parameter Efficiency**  | Large number of parameters, prone to overfitting | Fewer parameters due to shared weights and pooling |\n",
    "| **Spatial Awareness**     | Cannot capture spatial information or patterns directly | Captures spatial patterns (e.g., edges, textures) effectively |\n",
    "| **Performance on Images** | Performs poorly on image data without preprocessing | Highly efficient for image-related tasks |\n",
    "| **Training Time**         | Faster for smaller datasets | Longer due to complex operations like convolution |\n",
    "| **Generalization**        | Can overfit easily with limited data | Better generalization for visual data |\n",
    "| **Use Cases**             | Tabular data, financial models, time series forecasting | Image classification, object detection, facial recognition |\n",
    "| **Memory Requirements**   | Lower memory requirements | Higher memory requirements due to feature maps |\n",
    "| **Interpretability**      | Harder to interpret features | Easier to interpret filters (e.g., edge detection filters) |\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**  \n",
    "- **ANNs** are suitable for simpler tasks that involve non-spatial data like **time series** or **tabular datasets**.  \n",
    "- **CNNs** excel in **image processing tasks** because they can capture **spatial features** (such as edges and textures) through **convolution operations** and **weight sharing**.  \n",
    "\n",
    "CNNs offer significant improvements over ANNs in tasks involving complex visual data, at the cost of higher computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a breakdown of the **different types of convolution** commonly used in Convolutional Neural Networks (CNNs), along with their purpose and examples.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Standard Convolution (2D Convolution)**  \n",
    "- **Description:**  \n",
    "  The most basic type of convolution used to extract features from an input image by sliding a filter over the entire image.\n",
    "\n",
    "- **Use Case:**  \n",
    "  - Feature extraction in image classification and object detection models.\n",
    "\n",
    "- **Formula:**  \n",
    "  \\( \\text{Feature Map}(i, j) = \\sum_{m} \\sum_{n} \\text{Input}(i+m, j+n) \\cdot \\text{Filter}(m, n) \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Depthwise Convolution**  \n",
    "- **Description:**  \n",
    "  In this type, each input channel has its **own separate filter**, and the filters are not shared across channels.\n",
    "\n",
    "- **Use Case:**  \n",
    "  - Used in **MobileNet** architectures to reduce computation.\n",
    "\n",
    "- **Advantage:**  \n",
    "  - Reduces the number of parameters and computation compared to standard convolution.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Pointwise Convolution (1x1 Convolution)**  \n",
    "- **Description:**  \n",
    "  Uses a **1x1 filter** to combine the information from different channels without considering spatial dimensions.\n",
    "\n",
    "- **Use Case:**  \n",
    "  - Used in architectures like **Inception** networks and **MobileNet** to reduce dimensionality.\n",
    "\n",
    "- **Advantage:**  \n",
    "  - Reduces the depth (number of channels) while maintaining important features.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Depthwise Separable Convolution**  \n",
    "- **Description:**  \n",
    "  A combination of **depthwise convolution** followed by **pointwise convolution**. It separates spatial filtering and channel mixing.\n",
    "\n",
    "- **Use Case:**  \n",
    "  - Used in lightweight models like **MobileNet** and **Xception** to reduce computation.\n",
    "\n",
    "- **Advantage:**  \n",
    "  - Efficient in terms of computation and memory usage.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Transposed Convolution (Deconvolution)**  \n",
    "- **Description:**  \n",
    "  Used to **up-sample** an image (increase its spatial resolution). Often referred to as **deconvolution**.\n",
    "\n",
    "- **Use Case:**  \n",
    "  - Image generation (e.g., GANs), image segmentation (e.g., U-Net) where spatial size needs to be increased.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Dilated Convolution (Atrous Convolution)**  \n",
    "- **Description:**  \n",
    "  Introduces **gaps** (dilations) between kernel elements to expand the receptive field without increasing the number of parameters.\n",
    "\n",
    "- **Use Case:**  \n",
    "  - Used in **semantic segmentation** (e.g., DeepLab) to capture multi-scale information.\n",
    "\n",
    "- **Advantage:**  \n",
    "  - Increases receptive field size efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Circular Convolution**  \n",
    "- **Description:**  \n",
    "  Wraps around the input data when the filter exceeds its boundaries, treating the data as if it’s circular.\n",
    "\n",
    "- **Use Case:**  \n",
    "  - Useful in periodic data, like time series, where the start and end points are connected.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Grouped Convolution**  \n",
    "- **Description:**  \n",
    "  Splits input channels into **groups**, and each group gets its own set of filters.\n",
    "\n",
    "- **Use Case:**  \n",
    "  - Used in architectures like **ResNeXt** to improve efficiency.\n",
    "\n",
    "- **Advantage:**  \n",
    "  - Reduces computation by processing channel groups independently.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison of Convolution Types**  \n",
    "\n",
    "| **Convolution Type**           | **Purpose**                                | **Example Usage**              |\n",
    "|--------------------------------|--------------------------------------------|--------------------------------|\n",
    "| Standard Convolution (2D)      | Extract spatial features                   | Image classification          |\n",
    "| Depthwise Convolution          | Reduce computation                        | MobileNet                     |\n",
    "| Pointwise Convolution (1x1)    | Channel mixing and dimension reduction     | Inception Network             |\n",
    "| Depthwise Separable Convolution | Efficient spatial & channel processing    | MobileNet, Xception           |\n",
    "| Transposed Convolution         | Up-sampling the image                      | GANs, U-Net                   |\n",
    "| Dilated Convolution            | Large receptive field without more params | DeepLab for segmentation      |\n",
    "| Circular Convolution           | Handle periodic data                      | Time series analysis          |\n",
    "| Grouped Convolution            | Efficient computation                      | ResNeXt                       |\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**  \n",
    "Each type of convolution serves a specific purpose in computer vision tasks. Models like **MobileNet**, **DeepLab**, and **GANs** utilize specialized convolutions to balance between **accuracy and computational efficiency**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
